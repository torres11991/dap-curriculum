{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analytics\n",
    "\n",
    "![Python and Pandas!](./images/PythonAndPandas.png)\n",
    "\n",
    "## We are going to learn about ...\n",
    "\n",
    "- What is Pandas\n",
    "- Pandas & NumPy\n",
    "- Pandas and Jupyter Notebooks\n",
    "- What Pandas can do\n",
    "- Pandas Series\n",
    "- Pandas DataFrames\n",
    "    - Viewing \n",
    "    - Adding to a DataFrame\n",
    "    - Sorting DataFrames\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas\n",
    "\n",
    "- An open-source Python package that is most widely used for data science/data analysis and machine learning tasks. \n",
    "- Built on top of NumPy which provides support for multi-dimensional arrays.\n",
    "- References both “Panel Data” and “Python Data Analysis”\n",
    "- The name Pandas is derived from the word \"Panel Data\"\n",
    "- Created by Wes McKinney in 2008\n",
    "- Official documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide\n",
    "- Community tutorials: https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html\n",
    "\n",
    "## Pandas & NumPy\n",
    "\n",
    "- NumPy is a library that adds support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays\n",
    "- Pandas is a high-level data manipulation tool that is built on the NumPy package\n",
    "- Pandas offers an in-memory 2d table object called a DataFrame\n",
    "- A DataFrame is structured like a table or spreadsheet -- with rows and columns\n",
    "- There are a few functions that exist in NumPy that we use specifically on Pandas DataFrames\n",
    "- Just as the \"ndarray\" is the foundation of NumPy, the \"Series\" is the core object of Pandas\n",
    "- NumPy consumes less memory than Pandas, and is faster than Pandas\n",
    "- These two libraries are the best libraries for data science applications\n",
    "- Pandas mainly works with tabular data, whereas NumPy works with numerical data\n",
    "\n",
    "## Pandas & Jupyter Notebooks\n",
    "\n",
    "Jupyter Notebooks offer a good environment for using pandas to do data exploration and modeling, but pandas can also be used in text editors just as easily.\n",
    "\n",
    "Jupyter Notebooks give us the ability to execute code in a particular cell as opposed to running the entire file. This saves a lot of time when working with large datasets and complex transformations. \n",
    "\n",
    "Notebooks also provide an easy way to visualize pandas’ DataFrames and plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can Pandas do?\n",
    "\n",
    "Pandas can perform five significant steps required for processing and analysis of data, irrespective of the origin of the data, -- load, manipulate, prepare, model, and analyze.\n",
    "\n",
    "What’s cool about Pandas is that it takes data (like a CSV or TSV file, or a SQL database) and creates a Python object with rows and columns called a 'data frame' that looks very similar to table in statistical software (think Excel).\n",
    "\n",
    "In fact, with Pandas, you can do everything that makes world-leading data scientists vote Pandas as the best data analysis and manipulation Python tool available.\n",
    "\n",
    "### Pandas can do ...\n",
    "\n",
    "|    |    |\n",
    "|----|----|\n",
    "| Data Cleansing | Data fill |\n",
    "| Data normalization | Merges and joins |\n",
    "| Data visualization | Statistical analysis |\n",
    "| Data inspection | Loading and saving data |\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Using Pandas\n",
    "\n",
    "**Remember: Pandas is a Module.**\n",
    "\n",
    "You have to install it first, and NumPy is required:\n",
    "\n",
    "```python\n",
    "    pip install pandas\n",
    "```\n",
    "\n",
    "Then you have to import it at the beginning of every code file to use it:\n",
    "\n",
    "```python\n",
    "    import pandas as pd\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames & Series\n",
    "\n",
    "A Series is essentially a column, and a DataFrame is a two-dimensional table made up of a collection of Series.\n",
    "\n",
    "DataFrames and Series are quite similar in that many operations that you can do with one you can do with the other, such as filling in null values and calculating the mean\n",
    "\n",
    "![Pandas Series and DataFrames](./images/Pandas_series-and-dataframe.png)\n",
    "\n",
    "### Pandas Series\n",
    "\n",
    "- A Pandas Series is like a column in a table\n",
    "- It is a one-dimensional array holding data of any type\n",
    "- If nothing else is specified, the values of the series are labeled with their index numbers -- first value has index 0, second value has index 1 etc.\n",
    "- These labels can be used to access specified values in the series\n",
    "- With the index argument, you can name your own labels for the indexes of your series\n",
    "- When you have created labels, you can access an item by referring to the label\n",
    "- You can also use a key/value object, like a dictionary, when creating a Series\n",
    "- You can create a DataFrame from two Series\n",
    "\n",
    "### Pandas DataFrames\n",
    "\n",
    "- A Pandas DataFrame is a 2D data structure, like a 2 dimensional array, or a table with rows and columns\n",
    "- Pandas use the `loc` attribute to return one or more specified row(s)\n",
    "- With the index argument, you can name your own indexes\n",
    "- Use the named index in the `loc` attribute to return the specified row(s)\n",
    "- If your data sets are stored in a file, Pandas can load them into a DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Working with Series...\n",
    "\n",
    "In pandas, Series is a one-dimensional, labeled array, capable of holding any data type (integers, strings, floating-point numbers, Python objects, etc.). \n",
    "\n",
    "Series store data in sequential order. It is one-column information similar to a columns in an excel sheet/SQL table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Series Example\n",
    "\n",
    "Create a new Python file -- make sure it has a `.py` extension\n",
    "\n",
    "Type this code into your Python file, open the terminal, and run it...\n",
    "\n",
    "```python\n",
    "    import pandas as pd\n",
    "    age = [20, 40, 60]\n",
    "    years = pd.Series(age)\n",
    "    print(years)\n",
    "\n",
    "```\n",
    "> To run it in your terminal type ...\n",
    "\n",
    "```bash\n",
    "    python filename.py\n",
    "```\n",
    "\n",
    "> Note: For the MacOS crowd, the command needs to be **`python3 ...`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20\n",
      "1    40\n",
      "2    60\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "age = [20, 40, 60]\n",
    "years = pd.Series(age)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the location of a row in a series ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a row using the index value\n",
    "import pandas as pd\n",
    "\n",
    "age = [20, 40, 60]\n",
    "years = pd.Series(age)\n",
    "\n",
    "print(age[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Combine Two Series into a Pandas DataFrame\n",
    "\n",
    "Using the Pandas `.concat()`, `series.append()`, `Pandas.merge()`, or `dataFrame.join()` methods you can combine / merge two or more series into a DataFrame.\n",
    "\n",
    "#### 1.) Combine Two Series Using Pandas `.concat()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can combine multiple series along a particular axis (column-wise or row-wise)\n",
    "import pandas as pd\n",
    "\n",
    "# Create pandas Series\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"])\n",
    "fees = pd.Series([22000,25000,23000])\n",
    "discount  = pd.Series([1000,2300,1000])\n",
    "\n",
    "# Combine two Series\n",
    "df = pd.concat([courses, fees], axis=1)\n",
    "print(\"Concat 2 lists ...\\n\", df)\n",
    "\n",
    "# Combine multiple Series\n",
    "df = pd.concat([courses, fees, discount], axis=1)\n",
    "print(\"\\nConcat 3 lists ...\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that if a Series doesn’t contains names, and names are not provided for columns while merging, default numbers are assigned to columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series by assigning names to each column\n",
    "import pandas as pd\n",
    "\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "discount  = pd.Series([1000,2300,1000],name='discount')\n",
    "\n",
    "df = pd.concat([courses,fees,discount],axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you add custom indexes to a Series, the `combine()` method carries the same indexes to the created DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series with assigned indexes and provide custom column names to each\n",
    "import pandas as pd\n",
    "\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "discount  = pd.Series([1000,2300,1000],name='discount')\n",
    "\n",
    "# Assign Index to Series\n",
    "index_labels=['r1','r2','r3']\n",
    "courses.index = index_labels\n",
    "fees.index = index_labels\n",
    "discount.index = index_labels\n",
    "\n",
    "# Concat Series by Changing Names\n",
    "df = pd.concat({'Courses': courses,\n",
    "                'Course_Fee': fees,\n",
    "                'Course_Discount': discount},axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see how to reset the indexes using the `reset_index()` method. \n",
    "\n",
    "This moves the current index as a column and adds a new index to a combined DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series with assigned indexes and provide custom column names to each\n",
    "import pandas as pd\n",
    "\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "discount  = pd.Series([1000,2300,1000],name='discount')\n",
    "\n",
    "# Assign Index to Series\n",
    "index_labels = ['r1','r2','r3']\n",
    "courses.index = index_labels\n",
    "fees.index = index_labels\n",
    "discount.index = index_labels\n",
    "\n",
    "# Concat Series by Changing Names\n",
    "df=pd.concat({'Courses': courses,\n",
    "                'Course_Fee': fees,\n",
    "                'Course_Discount': discount},axis=1)\n",
    "\n",
    "#change the index to a column & create new index\n",
    "df = df.reset_index()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.) Combine Two Series Using `pandas.merge()`\n",
    "\n",
    "The Pandas `merge()` method is used to combine complex column-wise combinations of DataFrame similar to SQL-like joins. \n",
    "\n",
    "Pandas `merge()` can be used for all database join operations between DataFrame or named Series objects. You have to pass the extra parameter “name” to the series in this case.\n",
    "\n",
    "Syntax:- `pd.merge(S1, S2, right_index=True, left_index=True)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   courses   fees\n",
      "0    Spark  22000\n",
      "1  PySpark  25000\n",
      "2   Hadoop  23000\n"
     ]
    }
   ],
   "source": [
    "# Create Series by assigning names\n",
    "import pandas as pd\n",
    "\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "\n",
    "# using pandas series merge()\n",
    "df = pd.merge(courses, fees, right_index = True,\n",
    "                left_index = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.) Using `Series.append()` to Combine Two Series\n",
    "\n",
    "You can use `pandas.DataFrame(Series.append(Series,ignore_index=True))` to create a DataFrame by appending series to another series. \n",
    "\n",
    "Note that in this example it doesn’t create multiple columns instead it just appends as multiple row’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  all_courses\n",
      "0       Spark\n",
      "1     PySpark\n",
      "2      Hadoop\n",
      "3      Pandas\n",
      "4      Python\n",
      "5       Scala\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JUnger\\AppData\\Local\\Temp\\ipykernel_6716\\2138588425.py:7: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = pd.DataFrame(courses_am.append(courses_pm,\n"
     ]
    }
   ],
   "source": [
    "# Using Series.append()\n",
    "import pandas as pd\n",
    "\n",
    "courses_am = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"])\n",
    "courses_pm = pd.Series([\"Pandas\",\"Python\",\"Scala\"])\n",
    "\n",
    "df = pd.DataFrame(courses_am.append(courses_pm,\n",
    "                                    ignore_index = True),\n",
    "                    columns=['all_courses'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warning: Libraries and languages change over time!\n",
    "\n",
    "This error message from the example above:\n",
    "\n",
    "![Pandas Series and DataFrames](./images/futurewarning_depricated_method.png)\n",
    "\n",
    "Tells us not only that the method we are using \"append\" is marked for removal, it also suggests a replacement method. \n",
    "\n",
    "If this is the first time you have seen this error _(warning)_ then you will likely need to review the documentation to learn the features of the method and it's syntax. \n",
    "\n",
    "pandas.concat - https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.concat.html?highlight=concat#pandas.concat\n",
    "\n",
    "Let's rewrite our code and give it a test!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0\n",
      "0    Spark\n",
      "1  PySpark\n",
      "2   Hadoop\n",
      "3   Pandas\n",
      "4   Python\n",
      "5    Scala\n"
     ]
    }
   ],
   "source": [
    "# Using concat()\n",
    "import pandas as pd\n",
    "\n",
    "courses_am = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"])\n",
    "courses_pm = pd.Series([\"Pandas\",\"Python\",\"Scala\"])\n",
    "\n",
    "df = pd.DataFrame(pd.concat([courses_am,courses_pm], ignore_index=True))\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.) Combine Two Series Using `DataFrame.join()`\n",
    "\n",
    "You can also use `DataFrame.join()` to join two series. \n",
    "\n",
    "In order to use the `DataFrame.join()`, you need to have a DataFrame object. One way to get is by creating a DataFrame from some Series, and then use the DataFrame to combine with another Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   courses   fees\n",
      "0    Spark  22000\n",
      "1  PySpark  25000\n",
      "2   Hadoop  23000\n"
     ]
    }
   ],
   "source": [
    "# create Series with assigning names\n",
    "import pandas as pd\n",
    "\n",
    "courses = pd.Series([\"Spark\",\"PySpark\",\"Hadoop\"], name='courses')\n",
    "fees = pd.Series([22000,25000,23000], name='fees')\n",
    "\n",
    "# Using DataFrame.join()\n",
    "df = pd.DataFrame(courses).join(fees)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### Working with Dataframes ...\n",
    "\n",
    "There are many ways to create a DataFrame from scratch, but a great option is to just use a simple `dict`, and then pass it to the Pandas DataFrame constructor.\n",
    "\n",
    "Each (key, value) item in the dictionary will correspond to a column in the resulting DataFrame.\n",
    "\n",
    "The Index of this DataFrame is given by default on creation, but we could also create our own when we initialize the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchases DataFrame ...\n",
      "    apples  oranges\n",
      "0       3        0\n",
      "1       2        3\n",
      "2       0        7\n",
      "3       1        2\n",
      "\n",
      "Purchases w/ customer indexes ...\n",
      "         apples  oranges\n",
      "June         3        0\n",
      "Robert       2        3\n",
      "Lily         0        7\n",
      "David        1        2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dictionary\n",
    "data = {\n",
    "    'apples': [3, 2, 0, 1], \n",
    "    'oranges': [0, 3, 7, 2]\n",
    "}\n",
    "\n",
    "# pass the dict to the Pandas DataFrame constructor\n",
    "purchases = pd.DataFrame(data)\n",
    "print(\"Purchases DataFrame ...\\n\", purchases)\n",
    "\n",
    "# we could create our own indexes when we initialize the DataFrame\n",
    "purchases = pd.DataFrame(data, index=['June', 'Robert', 'Lily', 'David'])\n",
    "\n",
    "print(\"\\nPurchases w/ customer indexes ...\\n\", purchases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame Example\n",
    "\n",
    "Create a new Jupyter Notebook file -- make sure it has a `.ipynb` extension. You could run Jupyter inside VS Code or in the Jupyter Notebook console in the browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Classes  Grades\n",
      "0     Math      75\n",
      "1  Science      80\n",
      "2  Spanish      95\n",
      "3  History      60\n",
      "4   Health     100\n"
     ]
    }
   ],
   "source": [
    "# working with Pandas DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding the location of a row in a DataFrame...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes    History\n",
      "Grades          60\n",
      "Name: 3, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the location of a row\n",
    "import pandas as pd\n",
    "\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report)\n",
    "print(results.loc[3])\n",
    "type(results.loc[3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: This example above returns a Pandas Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the Location of More than 1 row\n",
    "import pandas as pd\n",
    "\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report)\n",
    "print(results.loc[[2, 3]])\n",
    "type(results.loc[[2, 3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: When using `[[ ]]` above, the result is a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming the rows / indexes\n",
    "import pandas as pd\n",
    "\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report, index = [\"week1\", \"week2\", \"week3\", \"week4\", \"week5\"])\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locating a specific row using the named indexes\n",
    "import pandas as pd\n",
    "\n",
    "Report = {\n",
    "    \"Classes\": [\"Math\", \"Science\", \"Spanish\", \"History\", \"Health\"],\n",
    "    \"Grades\": [75, 80, 95, 60, 100]\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(Report, index = [\"week1\", \"week2\", \"week3\", \"week4\", \"week5\"])\n",
    "print(results.loc[\"week3\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting DataFrames\n",
    "\n",
    "We'll look at different methods to sort a DataFrame\n",
    "\n",
    "- Sorting in Ascending order\n",
    "- Sorting in Descending order\n",
    "- Sorting by putting missing values first\n",
    "- Sorting by multiple columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing Pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# creating and initializing a nested list\n",
    "age_list = [['Afghanistan', 1952, 8425333, 'Asia'],\n",
    "            ['Australia', 1957, 9712569, 'Oceania'],\n",
    "            ['Brazil', 1962, 76039390, 'Americas'],\n",
    "            ['China', 1957, 637408000, 'Asia'],\n",
    "            ['France', 1957, 44310863, 'Europe'],\n",
    "            ['India', 1952, 3.72e+08, 'Asia'],\n",
    "            ['South Africa', 1966, 0.0, 'Africa'],\n",
    "            ['United States', 1957, 171984000, 'Americas']]\n",
    "\n",
    "# creating a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(age_list, columns=['Country', 'Year',\n",
    "                                    'Population', 'Continent'])\n",
    "print(\"Original DataFrame ...\\n\", df)\n",
    "\n",
    "#### ASCENDING EXAMPLE ####\n",
    "# Sorting the DataFrame in Ascending order -- Sorting by column 'Continent'\n",
    "df.sort_values(by = ['Continent'], inplace = True)\n",
    "# print(\"\\nDF sorted by Continent ...\\n\", df)\n",
    "\n",
    "\n",
    "#### DESCENDING EXAMPLE ####\n",
    "# Sorting the Data frame in Descending order -- Sorting by column \"Population\"\n",
    "df.sort_values(by = ['Country'], inplace = True, ascending = False)\n",
    "# print(\"\\nDF sorted by Country descending ...\\n\", df)\n",
    "\n",
    "\n",
    "#### MISSING VALUES EXAMPLE ####\n",
    "# Sorting column \"Population\" by putting missing values first\n",
    "df.sort_values(by = ['Population'], inplace = True, na_position = 'first')\n",
    "# print(\"\\nDF sorted by missing values first ...\\n\", df)\n",
    "\n",
    "\n",
    "#### MULTI COLUMN SORT EXAMPLE ####\n",
    "# Sorting by multiple columns -- \"Country\" and then \"Continent\"\n",
    "df.sort_values(by = ['Country', 'Continent'], inplace = True)\n",
    "# print(\"\\nDF sorting multiple columns ...\\n\", df)\n",
    "\n",
    "\n",
    "#### EXAMPLE SORT MULTI COLUMNS IN DIFFERENT ORDER ####\n",
    "# Sorting Data frames by multiple columns but different order\n",
    "# Sorting \"Country\" descending, and \"Continent\" ascending\n",
    "df.sort_values(by = ['Country', 'Continent'],\n",
    "                ascending = [False, True], inplace = True)\n",
    "# print(\"\\nDF sorting multiple columns in different order ...\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fun Facts regarding US 2020 census:\n",
    "\n",
    "https://usafacts.org/state-of-the-union/population/?msclkid=fe650f642143182d43d06c190597ba46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new column to existing DataFrame in Pandas\n",
    "\n",
    "We'll look at different methods to add a new column to a DataFrame\n",
    "- By declaring a new list as a column\n",
    "- By using `DataFrame.insert()`\n",
    "- Using `Dataframe.assign()` method\n",
    "- By using a dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas package\n",
    "import pandas as pd\n",
    "\n",
    "# Define a dictionary containing Students data\n",
    "data = {'Name': ['Jai', 'Princi', 'Gaurav', 'Anuj'],\n",
    "        'Height': [5.1, 6.2, 5.1, 5.2],\n",
    "        'Qualification': ['Msc', 'MA', 'Msc', 'Msc']}\n",
    "\n",
    "# Convert the dictionary into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame ...\\n\", df)\n",
    "\n",
    "\n",
    "#### LIST AS COLUMN EXAMPLE ####\n",
    "# Declare a list that is to be converted into a column\n",
    "address = ['Delhi', 'Bangalore', 'Chennai', 'Patna']\n",
    "# Using 'Address' as the column name and equating it to the list\n",
    "df['Address'] = address\n",
    "\n",
    "# print(\"\\nDF with column from list ...\\n\", df)\n",
    "\n",
    "\n",
    "#### INSERT EXAMPLE ####\n",
    "# Using DataFrame.insert() to add a column\n",
    "df.insert(2, \"Age\", [21, 23, 24, 21], True)\n",
    "\n",
    "# print(\"\\nDF with insert as column 2 ...\\n\", df)\n",
    "\n",
    "\n",
    "#### ASSIGN EXAMPLE ####\n",
    "# Using 'Address' as the column name and assign it to the list\n",
    "df = df.assign(Pets=['Dog', 'Bunny', 'Chinchilla', 'Parrot'])\n",
    "\n",
    "# print(\"\\nDF with assigned column added ...\\n\", df)\n",
    "\n",
    "\n",
    "#### DICTIONARY EXAMPLE ####\n",
    "# Define a dictionary with keys of an existing column\n",
    "# and their respective values as the values for our new column\n",
    "# If a primary key is defined use that key\n",
    "sport = {'Jai': 'Darts', 'Princi': 'Basketball',\n",
    "                'Gaurav': 'PaddleBoarding', 'Anuj': 'Cricket'}\n",
    "\n",
    "# Provide 'Sport' as the new column name and map it to the key column\n",
    "df['Sport'] = df['Name'].map(sport)\n",
    "print(\"\\nDF with new column from dictionary ...\\n\", df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View & Print a Summary of a DataFrame\n",
    "\n",
    "Data visualization is the technique used to deliver insights in data using visual cues such as graphs, charts, maps, and many others. \n",
    "\n",
    "This is useful as it permits intuitive and easy understanding of large quantities of data to facilitate making better business decisions. \n",
    "\n",
    "When we use a standard  print in Pandas like `print(df)`, by default, the complete data frame is not printed if the length exceeds the default length, the output is truncated.\n",
    "\n",
    "With this print statement, you get the first 5 lines & the last 5 lines With the row and column count of the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of printing a Pandas DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./resources/data.csv')\n",
    "\n",
    "# print first 5 & last 5 lines With the row and column count\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statement almost gives you the Whole DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./resources/data.csv')\n",
    "\n",
    "# note this Output Exceeds the size limit\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the Max Rows on your system with the max_rows command\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./resources/data.csv')\n",
    "\n",
    "print(pd.options.display.max_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the Max Rows setting on your system\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_rows = 9999\n",
    "\n",
    "df = pd.read_csv('./resources/data.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing the First or Last `N` rows of a DataFrame\n",
    "\n",
    "View the First or Last `N` number of rows from a DataFrame using the `.head()` OR `.tail()` commands. If you have an empty `.head()` or `.tail()` command, you get only the first or last FIVE (5) rows.\n",
    "\n",
    "    -   `print(df.head(10))`\n",
    "    -   `print(df.tail(10))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the FIRST or LAST 12 rows\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./resources/data.csv')\n",
    "\n",
    "# view the head\n",
    "print(df.head(12))\n",
    "\n",
    "# view the tail\n",
    "print(df.tail(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing information about the DataFrame\n",
    "\n",
    "You can view a summary of your DataFrame using the `.info()` command. If you print an empty info command, you get the DataFrame Summary.\n",
    "\n",
    "The information contains the number of columns, column labels, column data types, memory usage, range index, and the number of cells in each column (non-null values). \n",
    "\n",
    "> Note: the `.info()` method actually prints the info; You do not need use the `.print()` method to print the info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./resources/data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Below is a detailed explanation of the DataFrame `.info()` display**\n",
    "\n",
    "![Pandas DataFrame Info Display Explained](./images/Pandas_DF_InfoDisplay.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "In the next section we'll look at Data Ingestion with Pandas, particularly Pandas and .CSV files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
